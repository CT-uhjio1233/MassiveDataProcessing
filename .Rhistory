precision <- (cmKNN.factor[[1]]/sum(cmKNN.factor[,1]))
print(paste("預測",mycolName[1],"的正確率,precision=",round(precision,2)))
TPR <- (cmKNN.factor[[1]]/sum(cmKNN.factor[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",round(TPR,2)))
TNR <- (cmKNN.factor[[4]]/sum(cmKNN.factor[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",round(TNR,2)))
precision <- (cmKNN.factor[[4]]/sum(cmKNN.factor[,2]))
print(paste("預測",mycolName[2],"的正確率,precision=",round(precision,2)))
TPR <- (cmKNN.factor[[4]]/sum(cmKNN.factor[2,]))
print(paste("預測",mycolName[2],"的正確率,TPR=",round(TPR,2)))
TNR <- (cmKNN.factor[1]/sum(cmKNN.factor[1,]))
print(paste("預測",mycolName[2],"的正確率,TNR=",round(TNR,2)))
accuracy <- sum(diag(cmKNN.factor))/sum(cmKNN.factor)
print(paste("整體準確率=",round(accuracy,2)))
}else if(length(cmKNN.factor)==2){
precision <- (cmKNN.factor[[2]]/sum(cmKNN.factor[,1]))
paste("預測",mycolName[2],"的正確率,precision=",round(precision))
TPR <- (cmKNN.factor[[2]]/sum(cmKNN.factor[2,]))
print(paste("預測",mycolName[2],"的正確率,TPR=",round(TPR)))
accuracy <- sum(diag(cmKNN.factor)[[2]])/sum(cmKNN.factor[,1])
print(paste("整體準確率=",round(accuracy,2)))
}
print(cmKNN.factor)
klist <- seq(1:(kv+kv))
knnFunction <- function(x,knnTrain,knnTest,trainLabels,testLabels){
prediction <- knn(train = knnTrain,test=knnTest,cl=trainLabels,k=x)
cm <- table(x=testLabels,y=prediction)
accuracy <- sum(diag(cm))/sum(cm)
}
accuracies <- sapply(klist,knnFunction,knnTrain=knnTrain,knnTest=knnTest,trainLabels=trainLabels,testLabels=testdata$status)
df <- data.frame(kv=klist,accuracy=accuracies)
ggplot(df,aes(x=kv,y=accuracy,label=kv,color=accuracy))+geom_point(size=5)+geom_text(vjust=2)
trainLabels <- traindata$status
dim(train_labels)
dim(trainLabels)
trainLabels <- traindata$status
dim(trainLabels)
cl = trainLabels
trainLabels <- traindata$status
dim(trainLabels)
source('G:/RCode/knnforFinal.R', encoding = 'UTF-8')
source('G:/RCode/knnforFinal.R', encoding = 'UTF-8')
source('G:/RCode/R_Code_ANNforWin10.R', encoding = 'UTF-8')
source('G:/RCode/R_Code_ANNforWin10.R', encoding = 'UTF-8')
library(class)
library(dplyr)
if(!(packageName%in%rownames(installed.packages()))){
install.packages(packageName)
}
setwd("G:/RCode")
#測試模型,可隨機產生(訓練資料,測試資料)
traindata=read.csv("Parkinsons_Test.csv")
testdata=read.csv("Parkinsons_Test.csv")
#去除第一欄PK不適合分岔屬性
testdata <- testdata[-c(1)]
traindata <- traindata[-c(1)]
trainLabels <- traindata$status
knnTrain <- traindata[,-c(24)]
knnTest <- testdata[,-c(24)]
kv <- round(sqrt(length(knnTrain)))
prediction <- knn(train = knnTrain, test = knnTest, cl = trainLabels, k=kv)
cm <- table(testdata$status,prediction,dnn=c("實際","預測"))
print(cm)
if(length(cm)==4){
nycolName <- colnames(cm)
mycolName[1]
precision <- (cm[[1]]/sum(cm[,1]))
print(paste("預測",mycolName[1],"的正確率,precision=",round(precision,2)))
TPR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",round(TPR,2)))
TNR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",round(TNR,2)))
precision <- (cm[[4]]/sum(cm[,2]))
print(paste("預測",mycolName[2],"的正確率,precision=",round(precision,2)))
TPR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[2],"的正確率,TPR=",round(TPR,2)))
TNR <- (cm[1]/sum(cm[1,]))
print(paste("預測",mycolName[2],"的正確率,TNR=",round(TNR,2)))
accuracy <- sum(diag(cm))/sum(cm)
print(paste("整體準確率 accuracy=",round(accuracy,2)))
}else if(length(cm)==2){
cm
precision <- (cm[[2]]/sum(cm[,1]))
print(paste("預測",mycolName[2],"的正確率,precision=",round(precision,2)))
TPR <- (cm[[2]]/sum(cm[2,]))
print(paste("預測",mycolName[2],"的正確率,TPR=",round(TPR,2)))
accuracy <- sum(cm[[2]]/sum(cm[,1]))
print(paste("整體準確率 accuracy=",round(accuracy,2)))
cm
}
Real <- as.factor(ifelse(testdata$status==1,"Y","N"))
Pred <- as.factor(ifelse(prediction==1,"Y","N"))
cmKNN <- table(Real=Real,Pred=Pred)
print(cmKNN)
cmKNN.factor <- table(factor(Real,ordered=TRUE,levels=c("Y","N")),factor(Pred,ordered=TRUE,levels=c("Y","N")),dnn=c("Real","Pred"))
print(cmKNN.factor)
if(length(cmKNN.factor)==4){
mycolName <- colnames(cmKNN.factor)
mycolName[1]
precision <- (cmKNN.factor[[1]]/sum(cmKNN.factor[,1]))
print(paste("預測",mycolName[1],"的正確率,precision=",round(precision,2)))
TPR <- (cmKNN.factor[[1]]/sum(cmKNN.factor[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",round(TPR,2)))
TNR <- (cmKNN.factor[[4]]/sum(cmKNN.factor[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",round(TNR,2)))
precision <- (cmKNN.factor[[4]]/sum(cmKNN.factor[,2]))
print(paste("預測",mycolName[2],"的正確率,precision=",round(precision,2)))
TPR <- (cmKNN.factor[[4]]/sum(cmKNN.factor[2,]))
print(paste("預測",mycolName[2],"的正確率,TPR=",round(TPR,2)))
TNR <- (cmKNN.factor[1]/sum(cmKNN.factor[1,]))
print(paste("預測",mycolName[2],"的正確率,TNR=",round(TNR,2)))
accuracy <- sum(diag(cmKNN.factor))/sum(cmKNN.factor)
print(paste("整體準確率=",round(accuracy,2)))
}else if(length(cmKNN.factor)==2){
precision <- (cmKNN.factor[[2]]/sum(cmKNN.factor[,1]))
paste("預測",mycolName[2],"的正確率,precision=",round(precision))
TPR <- (cmKNN.factor[[2]]/sum(cmKNN.factor[2,]))
print(paste("預測",mycolName[2],"的正確率,TPR=",round(TPR)))
accuracy <- sum(diag(cmKNN.factor)[[2]])/sum(cmKNN.factor[,1])
print(paste("整體準確率=",round(accuracy,2)))
}
print(cmKNN.factor)
klist <- seq(1:(kv+kv))
knnFunction <- function(x,knnTrain,knnTest,trainLabels,testLabels){
prediction <- knn(train = knnTrain,test=knnTest,cl=trainLabels,k=x)
cm <- table(x=testLables,y=prediction)
accuracy <- sum(diag(cm))/sum(cm)
}
accuracies <- sapple(klist,knnFunction,knnTrain=knnTrain,knnTest=knnTest,trainLabels=trainLabels,testLabels=testdata$status)
df <- data.frame(kv=klist,accuracy=accuracies)
install.packages("ggplot2")
library(ggplot2)
ggplot(df,aes(x=kv,y=accuracy,label=kv,color=accuracy))+geom-point(size=5)+geom_text(vjust=2)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
source('G:/RCode/R_Code_ANNforMac.R', encoding = 'UTF-8')
source('G:/RCode/R_Code_ANNforWin10.R', encoding = 'UTF-8')
source('G:/RCode/ANNforRcode.R', encoding = 'UTF-8')
source('G:/RCode/ANNforRcode.R', encoding = 'UTF-8')
#install.package("neuralnet")
#install.package("nnet")
#install.package("caret")
require(neuralnet)#for neuralnet(),nn model
require(nnet)#for class.ind()
require(caret)#for train(),tune paramenters
setwd("G:/RCode")#設定工作目錄
#測試模型,可隨機產生.(訓練資料,測試資料)
#Parkinsons=read.csv("ParkinsonsANN.csv")
#去除第一欄(決策樹)PK欄位不適合分岔屬性
#Parkinsons<-Parksons[-c(1)]
#np=ceiling(0.1*nrow(Parkinsons))#無條件進位
#test.index=sample(1:nrow(Parkinsons),np)#取索引值,抽樣10%(np)個
#testdata=Parkinsons[test.index,]#設定測試資料
#traindata=Parkinsons[-test.index,]#設定訓練資料
traindata=read.csv("SPECTF_test.csv")
testdata=read.csv("SPECTF_train.csv")
#去除第一欄PK不適合分岔屬性
#原始資料就會變成像這樣
head(traindata)
formula.bpn <- as.formula(status ~ F1+F2+F3+F4+F5+F6+F7+F8+F9+F10+F11+F12+F13+F14+F15+F16+F17+F18+F19+F20+F21+F22)
bpn <- neuralnet(data=traindata,
formula=formula.bpn,
hidden=c(2),#一個隱藏層:2個node
learningrate=0.01,#leearing rate
threshold=0.01,#partial derivatives of the error function, a stopping criteria
stepmax=5e5#最大的iteration數=500000(5*10^5)
)
plot(bpn)
pred<- compute(bpn,testdata[1:22])
pred$net.result
#pred.result<-round(pre$net.result)
pred.result<-round(1/(1+exp(-pred$net.result)))
pred.result
cm <- table(testdata$status,pred.result)
print(cm)
if(length(cm)==4){
mycolNames<-colnames(cm)
mycolName[1]
precision <- (cm[[1]]/sum(cm[,1]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
precision <- (cm[[4]]/sum(cm[,2]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
accuracy <- sum(diag(cm))/sum(cm)
print(paste("整體準確率=",round(accuracy,2)))
}else{
print("confusuion matrix 的個數<4,需額外計算")
}
source('G:/RCode/ANNforRcode.R', encoding = 'UTF-8')
TNR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
require(neuralnet)#for neuralnet(),nn model
require(nnet)#for class.ind()
require(caret)#for train(),tune paramenters
setwd("G:/RCode")#設定工作目錄
traindata=read.csv("SPECTF_test.csv")
testdata=read.csv("SPECTF_train.csv")
#原始資料就會變成像這樣
head(traindata)
formula.bpn <- as.formula(status ~ F1+F2+F3+F4+F5+F6+F7+F8+F9+F10+F11+F12+F13+F14+F15+F16+F17+F18+F19+F20+F21+F22)
bpn <- neuralnet(data=traindata,
formula=formula.bpn,
hidden=c(2),#一個隱藏層:2個node
learningrate=0.01,#leearing rate
threshold=0.01,#partial derivatives of the error function, a stopping criteria
stepmax=5e5#最大的iteration數=500000(5*10^5)
)
plot(bpn)
pred<- compute(bpn,testdata[1:22])
pred$net.result
#pred.result<-round(pre$net.result)
pred.result<-round(1/(1+exp(-pred$net.result)))
pred.result
cm <- table(testdata$status,pred.result)
print(cm)
if(length(cm)==4){
mycolNames<-colnames(cm)
mycolName[1]
precision <- (cm[[1]]/sum(cm[,1]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
precision <- (cm[[4]]/sum(cm[,2]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
accuracy <- sum(diag(cm))/sum(cm)
print(paste("整體準確率=",round(accuracy,2)))
}else{
print("confusuion matrix 的個數<4,需額外計算")
}
if(length(cm)==4){
mycolNames<-colnames(cm)
mycolName[1]
precision <- (cm[[1]]/sum(cm[,1]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
precision <- (cm[[4]]/sum(cm[,2]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
accuracy <- sum(diag(cm))/sum(cm)
print(paste("整體準確率=",round(accuracy,2)))
}else{
print("confusuion matrix 的個數<4,需額外計算")
}
if(length(cm)==4){
mycolNames<-colnames(cm)
mycolName[1]
precision <- (cm[[1]]/sum(cm[,1]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
precision <- (cm[[4]]/sum(cm[,2]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
accuracy <- sum(diag(cm))/sum(cm)
print(paste("整體準確率=",round(accuracy,2)))
}else{
print("confusuion matrix 的個數<4,需額外計算")
}
precision <- (cm[[1]]/sum(cm[,1]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
precision <- (cm[[4]]/sum(cm[,2]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
accuracy <- sum(diag(cm))/sum(cm)
print(paste("整體準確率=",round(accuracy,2)))
if(length(cm)==4){
mycolNames<-colnames(cm)
mycolName[1]
precision <- (cm[[1]]/sum(cm[,1]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
precision <- (cm[[4]]/sum(cm[,2]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
accuracy <- sum(diag(cm))/sum(cm)
print(paste("整體準確率=",round(accuracy,2)))
}else{
print("confusuion matrix 的個數<4,需額外計算")
}
#install.package("neuralnet")
#install.package("nnet")
#install.package("caret")
require(neuralnet)#for neuralnet(),nn model
require(nnet)#for class.ind()
require(caret)#for train(),tune paramenters
setwd("G:/RCode")#設定工作目錄
#測試模型,可隨機產生.(訓練資料,測試資料)
#Parkinsons=read.csv("ParkinsonsANN.csv")
#去除第一欄(決策樹)PK欄位不適合分岔屬性
#Parkinsons<-Parksons[-c(1)]
#np=ceiling(0.1*nrow(Parkinsons))#無條件進位
#test.index=sample(1:nrow(Parkinsons),np)#取索引值,抽樣10%(np)個
#testdata=Parkinsons[test.index,]#設定測試資料
#traindata=Parkinsons[-test.index,]#設定訓練資料
traindata=read.csv("SPECTF_test.csv")
testdata=read.csv("SPECTF_train.csv")
#去除第一欄PK不適合分岔屬性
#原始資料就會變成像這樣
head(traindata)
formula.bpn <- as.formula(status ~ F1+F2+F3+F4+F5+F6+F7+F8+F9+F10+F11+F12+F13+F14+F15+F16+F17+F18+F19+F20+F21+F22)
bpn <- neuralnet(data=traindata,
formula=formula.bpn,
hidden=c(2),#一個隱藏層:2個node
learningrate=0.01,#leearing rate
threshold=0.01,#partial derivatives of the error function, a stopping criteria
stepmax=5e5#最大的iteration數=500000(5*10^5)
)
plot(bpn)
pred<- compute(bpn,testdata[1:22])
pred$net.result
#pred.result<-round(pre$net.result)
pred.result<-round(1/(1+exp(-pred$net.result)))
pred.result
cm <- table(testdata$status,pred.result)
print(cm)
if(length(cm)==4){
mycolNames<-colnames(cm)
mycolName[1]
precision <- (cm[[1]]/sum(cm[,1]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
precision <- (cm[[4]]/sum(cm[,2]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cm[[4]]/sum(cm[2,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cm[[1]]/sum(cm[1,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
accuracy <- sum(diag(cm))/sum(cm)
print(paste("整體準確率=",round(accuracy,2)))
}else{
print("confusuion matrix 的個數<4,需額外計算")
}
source('G:/RCode/BayesianTheoryForW10.R', encoding = 'UTF-8')
source('G:/RCode/DecisionTreeForWin10.R', encoding = 'UTF-8')
source('G:/RCode/BayesianTheoryForW10.R', encoding = 'UTF-8')
source('G:/RCode/BayesianTheoryForW10.R', encoding = 'UTF-8')
source('G:/RCode/BayesianTheoryForW10.R', encoding = 'UTF-8')
source('G:/RCode/BayesianProbabilityForFinal.R', encoding = 'UTF-8')
source('G:/RCode/BayesianProbabilityForFinal.R', encoding = 'UTF-8')
source('G:/RCode/BayesianProbabilityForFinal.R', encoding = 'UTF-8')
source('G:/RCode/RandomTreeForWin10.R', encoding = 'UTF-8')
source('G:/RCode/RandomTreeForFinal.R', encoding = 'UTF-8')
source('G:/RCode/RandomTreeForWin10.R', encoding = 'UTF-8')
source('G:/RCode/RandomTreeForFinal.R', encoding = 'UTF-8')
source('G:/RCode/RandomTreeForFinal.R', encoding = 'UTF-8')
#安裝package
#install.packages("randowForest")
packageName="randomForest"
if(!(packageName %in% rownames(installed.packages()))){
install.packages(packageName)
}
#載入library
library(randomForest)
#(1)載入資料
setwd('G:/RCode') #設定工作目錄(資料集存放的地方)
#(2)測試模型，可隨機產生。(訓練資料、測試資料)
#第一種分割方式:自己把資料分割好再做
traindata=read.csv("SPECTF_train.csv")
testdata=read.csv("SPECTF_test.csv")
#第二種分割方式:電腦把資料分割好再做
#parkinsons=read.csv(ParkinsonsANN.csv)
#去除第一欄(決策樹)PK欄位不適合分岔屬性
#parkinsons <- parkinsons[- c(1)]
#np = ceiling(0.1*nrow(Parkinsons)) #無條件近位
#test.index=sample(1:nrow(Parkinsons),np) #取索引值，抽樣10%(np)個
#testdata=Parkinsons[test.index,] #設定測試資料
#traindata=Parkinsons[-test.index,] #設定訓練資料
#(3)建立決策樹模型:因變數~自變數
Parkinsons.RF=randomForest(status~.,data=traindata,importance=TRUE,proximity=TRUE,ntree=500,na.action=na.fail)
#第一個參數(status~.):表示除了status屬性之外，其他屬性皆為模型之引數
#第二個參數(data):表示模型中含有變數的一組資料
#第三個參數(importance=TRUE):是否計算模型中各屬性之重要值，資料型態為布林
#第四個參數(proximty=TRUE):	是否計算模型的鄰近矩陣，此參數搭配含數MDSplot()使用，資料型態為布林
#第五個參數(ntree=500):表示森林中的樹木數量
#第六個參數(subset):表示選出的訓練集資料為第幾筆(此參數的資料格式為向量)，當data為整個資料集時
#第七個參數(na.action=na.fail):表示遺漏值之處理，na.fail表示不能出現遺漏值
#(4)畫圖
print(Parkinsons.RF)
plot(Parkinsons.RF)
#利用importance()函數，得到MeanDecreaseAccuracy與MeanDecreaseGini，
#值愈高就表示該屬性對於該模型的判別影響愈大，
#可以做為後續利用其他演算法建模時刪減屬性的依據。
importance(Parkinsons.RF)
#(5)預測
result <- predict(parkinsons.RF,newdata=testdata,type="class")
#(6)建立混淆矩陣(confusion matrix)觀察模型表現
cm <- table(testdata$status,result,dnn=c("x","y")) #x為實際y為預測
cm
mycolName <- colnames(cm)
mycolName[1]
#(6A)正確率
#計算正確率(precision)
precision <- (cm[[1]] / sum(cm[,1]))
paste("預測",mycolName[1],"的正確率，precision=",precision)
#計算正確率(TPR)
TPR <- (cm[[1]] / sum(cm[1,]))
paste("預測",mycolName[1],"的正確率，TPR=",TPR)
#計算戶正確率(TNR)
TNR <- (cm[[4]] / sum(cm[2,]))
paste("預測",mycolName[2],"的正確率，TNR=",TNR)
#(6B)正確率
#計算正確率(precision)
precision <- (cm[[4]] / sum(cm[,2]))
paste("預測",mycolName[2],"的正確率，precision=",precision)
#計算正確率(TPR)
TPR <- (cm[[4]] / sum(cm[2,]))
paste("預測",mycolName[2],"的正確率，TPR=",TPR)
#計算戶正確率(TNR)
TNR <- (cm[[1]] / sum(cm[1,]))
paste("預測",mycolName[2],"的正確率，TNR=",TNR)
#整體準確率(取出對角/總數)
accuracy <- sum(diag(cm)) / sum(cm)
paste("整體準確率 =",accuracy)
cm
#(6)建立混淆矩陣(confusion matrix)觀察模型表現
cmRF <- table(testdata$status,result,dnn=c("x","y")) #x為實際y為預測
cmRF.factor <- table(factor(testdata$status,ordered=TRUE,levels=c("Y","N")),factor(result,ordered=TRUE,levels=c("Y","N")),dnn=c("Real","Pred"))
cmRF.factor
source('G:/RCode/SVMforWin10.R', encoding = 'UTF-8')
source('G:/RCode/SVMforFinal.R', encoding = 'UTF-8')
setwd('G:/RCode')
traindata=read.csv("SPECTF_train.csv")
testdata=read.csv("SPECTF_test.csv")
testdata<-testdata[-c(1)]
traindata<-traindata[-c(1)]
packageName="e1071"
if(!(packageName %in%rownames(installed.packages()))){
install.packages(packageName)
}
library(e1071)
svmM<-svm(status~.,data=traindata,probability=TRUE)
results<-predict(svmM,testdata,probability=TRUE)
result.TR<-round(1/(1+exp(-results)))
Real<-as.factor(ifelse(testdata$status==1,"Y","N"))
Pred<-as.factor(ifelse(result.TR==1,"Y","N"))
cm<-table(R=Real,P=Pred)
cm
cmSVM<-table(Real=Real,Pred=Pred)
cmSVM
cmSVM.factor<-table(factor(Real,ordered=TRUE,levels=c("Y","N")),factor(Pred,order=TRUE,levels=c("Y","N")),dnn=c("Real","Pred"))
cmSVM.factor
SVMaccuracy<-round(sum(diag(cmSVM.factor))/sum(cmSVM.factor),4)
SVMaccuracy
if(length(cmSVM.factor)==4){
mycolNames<-colnames(cmSVM.factor)
mycolName[1]
precision <- (cmSVM.factor[[1]]/sum(cmSVM.factor[,1]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cmSVM.factor[[1]]/sum(cmSVM.factor[1,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cmSVM.factor[[4]]/sum(cmSVM.factor[2,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
precision <- (cmSVM.factor[[4]]/sum(cmSVM.factor[,2]))
paste("預測",mycolName[1],"的正確率,precision=",precision)
TPR <- (cmSVM.factor[[4]]/sum(cmSVM.factor[2,]))
print(paste("預測",mycolName[1],"的正確率,TPR=",TPR))
TNR <- (cmSVM.factor[[1]]/sum(cmSVM.factor[1,]))
print(paste("預測",mycolName[1],"的正確率,TNR=",TNR))
accuracy <- sum(diag(cmSVM.factor))/sum(cmSVM.factor)
print(paste("整體準確率=",round(accuracy,2)))
}else #if(length(cmSVM.factor)==2)
{
cmSVM.factor
precision <- (cmSVM.factor[[2]]/sum(cmSVM.factor[,1]))
print(paste("預測",mycolName[2],"的正確率,precision=",round(precision,2)))
TPR <- (cmSVM.factor[[2]]/sum(cmSVM.factor[2,]))
print(paste("預測",mycolName[2],"的正確率,TPR=",round(TPR,2)))
accuracy <- (cmSVM.factor[[2]]/sum(cmSVM.factor[,1]))
print(paste("整體準確率=",round(accuracy,2)))
}
cmSVM.factor
